{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fee4a92f",
   "metadata": {},
   "source": [
    "# Senitment Prediction for Robo Eye Animation\n",
    "\n",
    "The project, involves a dynamic robot eye animation displayed on a 0.96\" OLED screen that changes based on the sentiment of text input provided by the user. The hardware controller used for this project is the CAP10 Pratham, a made-in-India board. This project offers a unique way to integrate emotional intelligence into robotics, enabling bots to visually express emotions in response to user interactions.\n",
    "\n",
    "**Author:** Asutosh Pati ([https://www.linkedin.com/in/asutoshpati/](https://www.linkedin.com/in/asutoshpati/))  \n",
    "**Date:** 21-Aug-2024  \n",
    "**Versions:**  \n",
    "- V1.0: Initial Release\n",
    "- V1.1: Change communication method from Serial to API call",
    "- V2.0: Add text to speech functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6394d2",
   "metadata": {},
   "source": [
    "### Install & Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c93e4595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow==2.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37d19e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c39ff81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /home/santosh/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/santosh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004bf187",
   "metadata": {},
   "source": [
    "### Preprocess the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f090a337",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer= WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2f0615a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oh, yes! i have ssen that.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lower_case(text):\n",
    "    text = text.split()\n",
    "    text = [y.lower() for y in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "lower_case(\"Oh, Yes! I have ssen that.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eba2695d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Have you visited '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "remove_urls(\"Have you visited https://www.google.co.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9b1e53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Are you sure It s amazing'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punctuations(text):\n",
    "    # Remove punctuations\n",
    "    text = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,،-./:;<=>؟?@[\\]^_`{|}~\"\"\"), ' ', text)\n",
    "    text = text.replace('؛',\"\", )\n",
    "    \n",
    "    # remove extra whitespace\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text =  \" \".join(text.split())\n",
    "    return text.strip()\n",
    "\n",
    "remove_punctuations(\"Are you sure; It's amazing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50fb078b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Have you seen the prime minister's speech at  am\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_numbers(text):\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "    return text\n",
    "\n",
    "remove_numbers(\"Have you seen the prime minister's speech at 10 am\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2092d62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I good boy; true'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stop_words(text):\n",
    "    text = [i for i in str(text).split() if i not in stop_words]\n",
    "    return \" \".join(text)\n",
    "\n",
    "remove_stop_words(\"I am a very good boy; is it true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c750c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love to watch Footbal. What do you like to do?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatization(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = text.split()\n",
    "    text = [lemmatizer.lemmatize(y) for y in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "lemmatization(\"I love to watch Footbal. What do you like to do?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fce16ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arise awake stop goal reached swami vivekananda'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = lower_case(sentence)\n",
    "    sentence = remove_urls(sentence)\n",
    "    sentence = remove_punctuations(sentence)\n",
    "    sentence = remove_numbers(sentence)\n",
    "    sentence = remove_stop_words(sentence)\n",
    "    sentence = lemmatization(sentence)\n",
    "    return sentence\n",
    "\n",
    "preprocess_sentence(\"Arise, awake, and stop not until the goal is reached. - Swami Vivekananda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47006381",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "158b0576",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santosh/.conda/envs/llm/lib/python3.11/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.3.2 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# import label encoder created during training\n",
    "\n",
    "le = None\n",
    "with open(\"./model/label_encoder.pkl\",'rb') as file:\n",
    "    le = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d05b75a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tokenizer created during training\n",
    "\n",
    "tokenizer = None\n",
    "with open(\"./model/tokenizer.json\") as file:\n",
    "    tokenizer_json = file.read()\n",
    "    tokenizer = tokenizer_from_json(tokenizer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34827d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 229, 200)          2865000   \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 229, 512)          935936    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 229, 256)          656384    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirecti  (None, 229, 256)          394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirecti  (None, 229, 128)          164352    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirecti  (None, 128)               98816     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5115502 (19.51 MB)\n",
      "Trainable params: 2250502 (8.58 MB)\n",
      "Non-trainable params: 2865000 (10.93 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# import the pre-trained model\n",
    "\n",
    "model_path = \"./model/Sentiment_analysis_Eng-V3.h5\"\n",
    "model = load_model(model_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fdad28",
   "metadata": {},
   "source": [
    "### Use the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "753a4aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels ['fear', 'sadness', 'joy', 'anger', 'love', 'surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fdae9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 1s 585ms/step\n",
      "['joy'] : 0.3245931565761566\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'joy'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_emotion(text):\n",
    "    sentence = preprocess_sentence(text)\n",
    "    \n",
    "    sentence = tokenizer.texts_to_sequences([sentence])\n",
    "    sentence = pad_sequences(sentence, maxlen=229, truncating='pre')\n",
    "    \n",
    "    result = le.inverse_transform(np.argmax(model.predict(sentence), axis=-1))\n",
    "    proba =  np.max(model.predict(sentence))\n",
    "\n",
    "    # class_predict =  np.max(model.predict(sentence))\n",
    "    # print(class_predict)\n",
    "    \n",
    "    print(f\"{result} : {proba}\\n\\n\")\n",
    "    \n",
    "    return result[0]\n",
    "\n",
    "extract_emotion(\"Hurray!! My Model Got 93% Accuracy, Connect With me https://www.linkedin.com/in/asutoshpati/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01d5c502",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sentences = [\n",
    "    \"He's over the moon about being accepted to the university\",\n",
    "    \"Your point on this certain matter made me outrageous, how can you say so? This is insane.\",\n",
    "    \"I can't do it, I'm not ready to lose anything, just leave me alone\",\n",
    "    \"Merlin's beard harry, you can cast the Patronus charm! I'm amazed!\",\n",
    "    \"I am amazed, that you do it.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4d60e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He's over the moon about being accepted to the university\n",
      "1/1 [==============================] - 1s 586ms/step\n",
      "1/1 [==============================] - 1s 591ms/step\n",
      "['joy'] : 0.8274199962615967\n",
      "\n",
      "\n",
      "joy\n",
      "\n",
      "\n",
      "\n",
      "Your point on this certain matter made me outrageous, how can you say so? This is insane.\n",
      "1/1 [==============================] - 1s 577ms/step\n",
      "1/1 [==============================] - 1s 576ms/step\n",
      "['anger'] : 0.4897823929786682\n",
      "\n",
      "\n",
      "anger\n",
      "\n",
      "\n",
      "\n",
      "I can't do it, I'm not ready to lose anything, just leave me alone\n",
      "1/1 [==============================] - 1s 583ms/step\n",
      "1/1 [==============================] - 1s 597ms/step\n",
      "['fear'] : 0.3876216411590576\n",
      "\n",
      "\n",
      "fear\n",
      "\n",
      "\n",
      "\n",
      "Merlin's beard harry, you can cast the Patronus charm! I'm amazed!\n",
      "1/1 [==============================] - 1s 583ms/step\n",
      "1/1 [==============================] - 1s 594ms/step\n",
      "['surprise'] : 0.935206949710846\n",
      "\n",
      "\n",
      "surprise\n",
      "\n",
      "\n",
      "\n",
      "I am amazed, that you do it.\n",
      "1/1 [==============================] - 1s 590ms/step\n",
      "1/1 [==============================] - 1s 594ms/step\n",
      "['surprise'] : 0.29983246326446533\n",
      "\n",
      "\n",
      "surprise\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in example_sentences:\n",
    "    print(sentence)\n",
    "    print(extract_emotion(sentence))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07fa5bdf-f523-4b48-9d1f-eae31b08fdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyaudio\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "# !pip install --upgrade transformers datasets[audio] accelerate\n",
    "# !pip install whisperx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f7b335f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34940/3608104360.py:1: DeprecationWarning: 'audioop' is deprecated and slated for removal in Python 3.13\n",
      "  import audioop\n",
      "/home/santosh/.conda/envs/llm/lib/python3.11/site-packages/pyannote/audio/core/io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n"
     ]
    }
   ],
   "source": [
    "import audioop\n",
    "import gc\n",
    "import os\n",
    "import pyaudio\n",
    "import torch\n",
    "import uuid\n",
    "import wave\n",
    "import whisperx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05454ce3-43b1-4011-8e5b-b532c4d2e9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whisper Model Parameters\n",
    "WHISPER_MODEL_NAME = \"small.en\"\n",
    "COMPUTE_DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# use \"float16\" for GPU & \"int8\" for CPU\n",
    "COMPUTE_DTYPE = \"float16\" if COMPUTE_DEVICE == \"cuda\" else \"int8\"\n",
    "SUPRESS_NUMERALS = True\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efdd5960-6ddd-4b43-8ba3-e87f7ceb2705",
   "metadata": {},
   "outputs": [],
   "source": [
    "RECORD_DIR =\"./recordings\"\n",
    "\n",
    "# Create a directory to store recordings if it doesn't exist\n",
    "if not os.path.exists(RECORD_DIR):\n",
    "    os.makedirs(RECORD_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78b7b2d8-0f21-40e0-9197-3ab588f4f20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../.cache/torch/whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.4.1+cpu. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    }
   ],
   "source": [
    "# Load the whisper model\n",
    "whisper_model = whisperx.load_model(\n",
    "    WHISPER_MODEL_NAME,\n",
    "    COMPUTE_DEVICE,\n",
    "    compute_type=COMPUTE_DTYPE,\n",
    "    # asr_options={\"suppress_numerals\": SUPRESS_NUMERALS}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57b9a88e-5c3d-4af1-bd79-fae7fc0d982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_audio(frames, target_rms=1000):\n",
    "    # Adjust audio frames to a target RMS for improved sound quality\n",
    "    rms = audioop.rms(b''.join(frames), 2)\n",
    "    gain = target_rms / (rms + 1)  # Avoid division by zero\n",
    "    normalized_frames = [audioop.mul(frame, 2, gain) for frame in frames]\n",
    "    return normalized_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac5cdcd9-b353-4136-86fe-f8f6814fe26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio(silence_threshold=1000, silence_duration=2):\n",
    "    chunk = 1024\n",
    "    audio_format = pyaudio.paInt16\n",
    "    channels = 1\n",
    "    rate = 44100\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=audio_format, channels=channels, rate=rate, input=True, frames_per_buffer=chunk)\n",
    "\n",
    "    print(\"Recording...\")\n",
    "    frames = []\n",
    "    silence_count = 0\n",
    "\n",
    "    while True:\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "        rms = audioop.rms(data, 2)\n",
    "        if rms < silence_threshold:\n",
    "            silence_count += 1\n",
    "        else:\n",
    "            silence_count = 0\n",
    "\n",
    "        if silence_count >= silence_duration * (rate / chunk):\n",
    "            print(\"Silence detected. Stopping recording.\")\n",
    "            break\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    # Normalize audio\n",
    "    normalized_frames = normalize_audio(frames)\n",
    "\n",
    "    output_filename = str(uuid.uuid4()) + \".wav\"\n",
    "    output_filename = os.path.join(os.getcwd(), RECORD_DIR, output_filename)\n",
    "\n",
    "    with wave.open(output_filename, 'wb') as wf:\n",
    "        wf.setnchannels(channels)\n",
    "        wf.setsampwidth(p.get_sample_size(audio_format))\n",
    "        wf.setframerate(rate)\n",
    "        wf.writeframes(b''.join(normalized_frames))\n",
    "\n",
    "    print(f\"Audio saved to {output_filename}\")\n",
    "    return output_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88dcfe40-862e-4cee-a1b9-74366587cf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio(audio_file):\n",
    "    global BATCH_SIZE\n",
    "    global whisper_model\n",
    "\n",
    "    audio = whisperx.load_audio(audio_file)\n",
    "    result = whisper_model.transcribe(audio, batch_size=BATCH_SIZE)\n",
    "    # print(result[\"segments\"])  # before alignment\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    # del whisper_model\n",
    "\n",
    "    return result[\"segments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c580a3a-6cfb-46be-911f-1d084771af1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_transcribe(processed_transcribe):\n",
    "    return \" \".join([sentence[\"text\"] for sentence in processed_transcribe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2944ccf2-ad94-4e38-8810-1673ac16e734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out the speech to text code",
    "# recorded_file = record_audio(silence_threshold=500, silence_duration=2)\n",
    "# transcribe = process_audio(recorded_file)\n",
    "# final_text = get_text_from_transcribe(transcribe)\n",
    "# print(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04979121-d3ea-48ff-be30-9107e620a8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text_process():\n",
    "    recorded_file = record_audio(silence_threshold=500, silence_duration=2)\n",
    "    transcribe = process_audio(recorded_file)\n",
    "    final_text = get_text_from_transcribe(transcribe)\n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e700447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_mood_mapping = {\"fear\": \"F\", \"sadness\": \"S\", \"joy\": \"H\", \"anger\": \"A\", \"love\": \"L\", \"surprise\": \"N\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "166384a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def send_mood(mood):\n",
    "    url = 'http://192.168.1.1'\n",
    "\n",
    "    try:\n",
    "        payload = {'mood': mood}\n",
    "        response = requests.get(url, params=payload, timeout=2)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            print(\"Request sent to bot\")\n",
    "            return None\n",
    "        else:\n",
    "            print('Error:', response.status_code)\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print('Error:', e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36ee3cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few examples that you can try\n",
    "# Hey, I have a good news for you. are you amazed! - surprise\n",
    "# Its your birthday, I have gift for you. aren't you happy. - joy\n",
    "# What you've done has left me heartbroken. - sadness\n",
    "# Are you afraid that I know what you have done ? - fear\n",
    "# For your nasty work I am going to scold you - anger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "040d9727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to connect with CAP10 before running this cell\n",
    "# Test with user input text\n",
    "\n",
    "# text = input(\"Enter your text: \")\n",
    "# emotion = extract_emotion(text)\n",
    "# mood = emotion_mood_mapping.get(emotion)\n",
    "# send_mood(mood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be09cac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:641:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1089:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port\n",
      "ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port\n",
      "ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card\n",
      "ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card\n",
      "ALSA lib pcm_dmix.c:1089:(snd_pcm_dmix_open) unable to open slave\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Silence detected. Stopping recording.\n",
      "Audio saved to /home/santosh/sentiment/Ani-Emo-Eye-master/./recordings/d884d34e-0547-4bf1-bf0d-610a0aad19dc.wav\n",
      " The cake taste delicious\n",
      "1/1 [==============================] - 1s 590ms/step\n",
      "1/1 [==============================] - 1s 584ms/step\n",
      "['joy'] : 0.9997907280921936\n",
      "\n",
      "\n",
      "joy\n",
      "H\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:641:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1089:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port\n",
      "ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port\n",
      "ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card\n",
      "ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card\n",
      "ALSA lib pcm_dmix.c:1089:(snd_pcm_dmix_open) unable to open slave\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Silence detected. Stopping recording.\n",
      "Audio saved to /home/santosh/sentiment/Ani-Emo-Eye-master/./recordings/311a1d0e-9cde-4ab5-9cf7-978c20244bd0.wav\n",
      " You have got to have a positive attitude to do well in life.\n",
      "1/1 [==============================] - 1s 600ms/step\n",
      "1/1 [==============================] - 1s 607ms/step\n",
      "['joy'] : 0.5851826667785645\n",
      "\n",
      "\n",
      "joy\n",
      "H\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:641:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1089:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port\n",
      "ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port\n",
      "ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card\n",
      "ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card\n",
      "ALSA lib pcm_dmix.c:1089:(snd_pcm_dmix_open) unable to open slave\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:641:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1089:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port\n",
      "ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port\n",
      "ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card\n",
      "ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card\n",
      "ALSA lib pcm_dmix.c:1089:(snd_pcm_dmix_open) unable to open slave\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Silence detected. Stopping recording.\n",
      "Audio saved to /home/santosh/sentiment/Ani-Emo-Eye-master/./recordings/299a46af-d9dc-4171-ac79-2f3dac424ab9.wav\n",
      " Donald was angry\n",
      "1/1 [==============================] - 1s 612ms/step\n",
      "1/1 [==============================] - 1s 590ms/step\n",
      "['anger'] : 0.6154758334159851\n",
      "\n",
      "\n",
      "anger\n",
      "A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:641:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1089:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port\n",
      "ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port\n",
      "ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card\n",
      "ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card\n",
      "ALSA lib pcm_dmix.c:1089:(snd_pcm_dmix_open) unable to open slave\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Silence detected. Stopping recording.\n",
      "Audio saved to /home/santosh/sentiment/Ani-Emo-Eye-master/./recordings/6394b1d5-0c75-439d-9568-616efb2b24c4.wav\n",
      " He shared that he had no anger towards the person who shot him.\n",
      "1/1 [==============================] - 1s 594ms/step\n",
      "1/1 [==============================] - 1s 587ms/step\n",
      "['fear'] : 0.4474654495716095\n",
      "\n",
      "\n",
      "fear\n",
      "F\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:641:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1089:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port\n",
      "ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port\n",
      "ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card\n",
      "ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card\n",
      "ALSA lib pcm_dmix.c:1089:(snd_pcm_dmix_open) unable to open slave\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Silence detected. Stopping recording.\n",
      "Audio saved to /home/santosh/sentiment/Ani-Emo-Eye-master/./recordings/96a5241b-593a-4627-99ff-2348a39b35ef.wav\n",
      "No active speech found in audio\n",
      "\n",
      "1/1 [==============================] - 1s 602ms/step\n",
      "1/1 [==============================] - 1s 618ms/step\n",
      "['fear'] : 0.37230420112609863\n",
      "\n",
      "\n",
      "fear\n",
      "F\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:641:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1089:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port\n",
      "ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port\n",
      "ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card\n",
      "ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card\n",
      "ALSA lib pcm_dmix.c:1089:(snd_pcm_dmix_open) unable to open slave\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Silence detected. Stopping recording.\n",
      "Audio saved to /home/santosh/sentiment/Ani-Emo-Eye-master/./recordings/329ba4f9-52a9-47d3-b1b2-e91b31bf3cd5.wav\n",
      " The kids are also now angry at me for pulling the vlog.\n",
      "1/1 [==============================] - 1s 602ms/step\n",
      "1/1 [==============================] - 1s 596ms/step\n",
      "['anger'] : 0.6040207147598267\n",
      "\n",
      "\n",
      "anger\n",
      "A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:641:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1089:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port\n",
      "ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port\n",
      "ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card\n",
      "ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card\n",
      "ALSA lib pcm_dmix.c:1089:(snd_pcm_dmix_open) unable to open slave\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Silence detected. Stopping recording.\n",
      "Audio saved to /home/santosh/sentiment/Ani-Emo-Eye-master/./recordings/68df3e3e-36f9-4e31-9adb-9d3cb48c3b1a.wav\n",
      " I'm anxious to go as soon as possible.\n",
      "1/1 [==============================] - 1s 591ms/step\n",
      "1/1 [==============================] - 1s 597ms/step\n",
      "['fear'] : 0.3879314661026001\n",
      "\n",
      "\n",
      "fear\n",
      "F\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:641:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1089:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port\n",
      "ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port\n",
      "ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card\n",
      "ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card\n",
      "ALSA lib pcm_dmix.c:1089:(snd_pcm_dmix_open) unable to open slave\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Silence detected. Stopping recording.\n",
      "Audio saved to /home/santosh/sentiment/Ani-Emo-Eye-master/./recordings/b000d68e-4390-4e31-bb55-9d749cba91c7.wav\n",
      " What a nice surprise.\n",
      "1/1 [==============================] - 1s 602ms/step\n",
      "1/1 [==============================] - 1s 610ms/step\n",
      "['surprise'] : 0.7299973964691162\n",
      "\n",
      "\n",
      "surprise\n",
      "N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:641:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1089:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port\n",
      "ALSA lib pcm_oss.c:377:(_snd_pcm_oss_open) Unknown field port\n",
      "ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card\n",
      "ALSA lib pcm_usb_stream.c:486:(_snd_pcm_usb_stream_open) Invalid type for card\n",
      "ALSA lib pcm_dmix.c:1089:(snd_pcm_dmix_open) unable to open slave\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m LISTENING_DELAY \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m     text \u001b[38;5;241m=\u001b[39m speech_to_text_process()\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(text)\n\u001b[1;32m      5\u001b[0m     emotion \u001b[38;5;241m=\u001b[39m extract_emotion(text)\n",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m, in \u001b[0;36mspeech_to_text_process\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mspeech_to_text_process\u001b[39m():\n\u001b[0;32m----> 2\u001b[0m     recorded_file \u001b[38;5;241m=\u001b[39m record_audio(silence_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, silence_duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      3\u001b[0m     transcribe \u001b[38;5;241m=\u001b[39m process_audio(recorded_file)\n\u001b[1;32m      4\u001b[0m     final_text \u001b[38;5;241m=\u001b[39m get_text_from_transcribe(transcribe)\n",
      "Cell \u001b[0;32mIn[25], line 15\u001b[0m, in \u001b[0;36mrecord_audio\u001b[0;34m(silence_threshold, silence_duration)\u001b[0m\n\u001b[1;32m     12\u001b[0m silence_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 15\u001b[0m     data \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mread(chunk)\n\u001b[1;32m     16\u001b[0m     frames\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[1;32m     17\u001b[0m     rms \u001b[38;5;241m=\u001b[39m audioop\u001b[38;5;241m.\u001b[39mrms(data, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/llm/lib/python3.11/site-packages/pyaudio/__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[0;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mread_stream(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream, num_frames,\n\u001b[1;32m    571\u001b[0m                       exception_on_overflow)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LISTENING_DELAY = 10\n",
    "while True:\n",
    "    text = speech_to_text_process()\n",
    "    print(text)\n",
    "    emotion = extract_emotion(text)\n",
    "    print(emotion)\n",
    "    mood = emotion_mood_mapping.get(emotion)\n",
    "    print(mood)\n",
    "    # send_mood(mood)  # Send information to bot\n",
    "    time.sleep(LISTENING_DELAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb701f63-286c-4a09-ba1c-b23acc5a5cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
